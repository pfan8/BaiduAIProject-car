{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle.fluid as fluid\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from utils.pickle_io import *\n",
    "import utils.config as config\n",
    "import utils.wv_loader as wv_loader\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(fluid.dygraph.Layer):\n",
    "    def __init__(self, \n",
    "                 name_scope, \n",
    "                 enc_units, \n",
    "                 batch_size, \n",
    "                 vocab_size=1e5, \n",
    "                 word_vector=None,\n",
    "                 param_attr=None,\n",
    "                 bias_attr=None,\n",
    "                 is_reverse=False,\n",
    "                 gate_activation='sigmoid',\n",
    "                 candidate_activation='tanh',\n",
    "                 h_0=None,\n",
    "                 origin_mode=False):\n",
    "        '''\n",
    "            Encoder初始化\n",
    "            :param name_scope: 所在命名空间\n",
    "            :param enc_units:GRU单元维度\n",
    "            :param batch_size: Batch数量\n",
    "            :param wordvector: 自定义词向量\n",
    "            \n",
    "        '''\n",
    "        super(Encoder, self).__init__(name_scope)\n",
    "        self.enc_units = int(enc_units)\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.vocab_size = int(vocab_size)\n",
    "        self.word_vector = word_vector\n",
    "        \n",
    "        # Embedding\n",
    "        if self.word_vector is not None:\n",
    "            self.vocab_size = int(self.word_vector.shape[0])\n",
    "            w_param_attrs = fluid.ParamAttr(\n",
    "                                name=\"emb_weight\",\n",
    "                                learning_rate=0.5,\n",
    "                                initializer=fluid.initializer.NumpyArrayInitializer(self.word_vector),\n",
    "                                trainable=True)\n",
    "            self._embedding = fluid.dygraph.Embedding(\n",
    "                                name_scope='embedding',\n",
    "                                size=list(self.word_vector.shape),\n",
    "                                param_attr= w_param_attrs,\n",
    "                                is_sparse=False)\n",
    "            # 如果有自定义词向量维度不符合 D*3，需要添加一层FC\n",
    "            if self.word_vector.shape[1] != self.enc_units*3:\n",
    "                self._fc = fluid.dygraph.FC('fc_for_gru', self.enc_units*3)\n",
    "        else:\n",
    "            self._embedding = fluid.dygraph.Embedding(\n",
    "                                name_scope='embedding',\n",
    "                                size=[self.vocab_size, self.enc_units*3],\n",
    "                                param_attr='emb.w',\n",
    "                                is_sparse=False)\n",
    "        \n",
    "        # GRU\n",
    "        self._gru = fluid.dygraph.GRUUnit(\n",
    "            self.full_name(),\n",
    "            size=self.enc_units * 3,\n",
    "            param_attr=param_attr,\n",
    "            bias_attr=bias_attr,\n",
    "            activation=candidate_activation,\n",
    "            gate_activation=gate_activation,\n",
    "            origin_mode=origin_mode)\n",
    "        self.h_0 = h_0 if h_0 is not None else self.initialize_hidden_state()\n",
    "        self.is_reverse = is_reverse\n",
    "                                                \n",
    "    \n",
    "    def forward(self, inputs, hidden=None):\n",
    "        '''\n",
    "        调用Encoder时的计算\n",
    "        :param inputs: variable类型的输入数据，维度（ N, T, D ）\n",
    "        :param hidden: 隐藏层输入h_0\n",
    "        :return output,state: output = hidden拼接向量，维度（ N, T, H ）\n",
    "                              state = hidden时间维度的最后一个向量\n",
    "        '''\n",
    "        hidden = self.h_0 if hidden is None else hidden\n",
    "        res = []\n",
    "        for i in range(inputs.shape[1]):\n",
    "            if self.is_reverse:\n",
    "                i = inputs.shape[1] - 1 - i\n",
    "            input_ = inputs[:, i:i + 1, :]\n",
    "            input_ = fluid.layers.reshape(\n",
    "                input_, [-1, input_.shape[2]], inplace=False)\n",
    "            input_ = self._embedding(inputs)\n",
    "            if hasattr(self, '_fc'):\n",
    "                input_ = self._fc(input_)\n",
    "            hidden, reset, gate = self._gru(input_, hidden)\n",
    "            hidden_ = fluid.layers.reshape(\n",
    "                hidden, [-1, 1, hidden.shape[1]], inplace=False)\n",
    "            res.append(hidden_)\n",
    "        if self.is_reverse:\n",
    "            res = res[::-1]\n",
    "        res = fluid.layers.concat(res, axis=1)\n",
    "        return res, res[:,-1,:]\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return fluid.layers.zeros((self.batch_size, self.enc_units), dtype='float32')\n",
    "\n",
    "class BahdanauAttention(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope, units):\n",
    "        super(BahdanauAttention, self).__init__(name_scope)\n",
    "        self.W1 = fluid.dygraph.FC('attention_fc1', units, num_flatten_dims=2)\n",
    "        self.W2 = fluid.dygraph.FC('attention_fc2', units, num_flatten_dims=2)\n",
    "        self.V = fluid.dygraph.FC('attention_v', 1, num_flatten_dims=2)\n",
    "\n",
    "    def forward(self, query, values):\n",
    "        # query shape == (batch_size, 1, hidden_size)\n",
    "        # values shape == (batch_size, max_length, hidden_size)\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        temp = (self.W1(values) + self.W2(query))\n",
    "        score = self.V(fluid.layers.tanh(temp))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = fluid.layers.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        # paddlepaddle will not do broadcast autom atically, use elementwise_mul API\n",
    "        context_vector = fluid.layers.elementwise_mul(values, attention_weights)\n",
    "        context_vector = fluid.layers.reduce_sum(context_vector, dim=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "class Decoder(fluid.dygraph.Layer):\n",
    "    def __init__(self, \n",
    "                 name_space, \n",
    "                 dec_units,\n",
    "                 batch_size,\n",
    "                 vocab_size=1e5, \n",
    "                 word_vector=None,\n",
    "                 param_attr=None,\n",
    "                 bias_attr=None,\n",
    "                 is_reverse=False,\n",
    "                 gate_activation='sigmoid',\n",
    "                 candidate_activation='tanh',\n",
    "                 h_0=None,\n",
    "                 origin_mode=False):\n",
    "        super(Decoder, self).__init__(name_space)\n",
    "        self.batch_size = int(batch_size)\n",
    "        self.dec_units = int(dec_units)\n",
    "        self.vocab_size = int(vocab_size)\n",
    "        self.word_vector = word_vector\n",
    "        \n",
    "       # Embedding\n",
    "        if self.word_vector is not None:\n",
    "            self.vocab_size = int(self.word_vector.shape[0])\n",
    "            w_param_attrs = fluid.ParamAttr(\n",
    "                                name=\"emb_weight\",\n",
    "                                learning_rate=0.5,\n",
    "                                initializer=fluid.initializer.NumpyArrayInitializer(self.word_vector),\n",
    "                                trainable=True)\n",
    "            self._embedding = fluid.dygraph.Embedding(\n",
    "                                name_scope='embedding',\n",
    "                                size=list(self.word_vector.shape),\n",
    "                                param_attr= w_param_attrs,\n",
    "                                is_sparse=False)\n",
    "        else:\n",
    "            self._embedding = fluid.dygraph.Embedding(\n",
    "                                name_scope='embedding',\n",
    "                                size=[self.vocab_size, self.dec_units*3],\n",
    "                                param_attr='emb.w',\n",
    "                                is_sparse=False)\n",
    "        \n",
    "        # GRU\n",
    "        self._gru = fluid.dygraph.GRUUnit(\n",
    "            self.full_name(),\n",
    "            size=self.dec_units * 3,\n",
    "            param_attr=param_attr,\n",
    "            bias_attr=bias_attr,\n",
    "            activation=candidate_activation,\n",
    "            gate_activation=gate_activation,\n",
    "            origin_mode=origin_mode)\n",
    "        \n",
    "        # 如果维度不符合 D*3 不能传导，需要添加一层FC，保证维度是 D*3\n",
    "        self._fc4gru = fluid.dygraph.FC('fc_for_gru', self.dec_units*3)\n",
    "        \n",
    "        # FC (N,H)==>(N,V)\n",
    "        # self._fc = fluid.dygraph.FC('fc', self.vocab_size, act='softmax')\n",
    "        self.is_reverse = is_reverse\n",
    "        \n",
    "    def forward(self, inputs, hidden, context_vector):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        # initial hidden is the last step of enc_output, hidden shape == (batch_size, hidden_size)\n",
    "        inputs = self._embedding(inputs)\n",
    "        # after concat shape is (batch_size, context_size + embedding_size)\n",
    "        inputs = fluid.layers.concat([context_vector, inputs], axis=-1)\n",
    "        inputs = self._fc4gru(inputs)\n",
    "        \n",
    "        hidden, reset, gate = self._gru(inputs, hidden)\n",
    "\n",
    "        # output = self._fc(hidden)\n",
    "        \n",
    "        return hidden, gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(fluid.dygraph.Layer):\n",
    "    def __init__(self, name_scope, params):\n",
    "        super(Seq2Seq, self).__init__(name_scope)\n",
    "        self.embedding_matrix = wv_loader.load_embedding_matrix()\n",
    "        self.params = params\n",
    "        self.encoder = Encoder('encoder',\n",
    "                               enc_units   = params[\"enc_units\"],\n",
    "                               batch_size  = params[\"batch_size\"],\n",
    "                               word_vector = self.embedding_matrix)\n",
    "\n",
    "        self.attention = BahdanauAttention('attention', params[\"attn_units\"])\n",
    "\n",
    "        self.decoder = Decoder('decoder',\n",
    "                               dec_units   = params[\"dec_units\"],\n",
    "                               batch_size  = params[\"batch_size\"],\n",
    "                               word_vector = self.embedding_matrix)\n",
    "\n",
    "    def call_encoder(self, enc_inp):\n",
    "        enc_hidden = self.encoder.initialize_hidden_state()\n",
    "        enc_output, enc_hidden = self.encoder(enc_inp, enc_hidden)\n",
    "        return enc_output, enc_hidden\n",
    "\n",
    "    def call_decoder_onestep(self, dec_input, dec_hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(dec_hidden, enc_output)\n",
    "\n",
    "        pred, dec_hidden = self.decoder(dec_input,\n",
    "                                        None,\n",
    "                                        context_vector)\n",
    "        return pred, dec_hidden, context_vector, attention_weights\n",
    "\n",
    "    def forward(self, dec_hidden, enc_output, dec_target):\n",
    "        predictions = []\n",
    "        attentions = []\n",
    "        \n",
    "        # print('enc_output shape:{}'.format(enc_output.shape))\n",
    "        context_vector, attn = self.attention(fluid.layers.reshape(dec_hidden,[dec_hidden.shape[0],1,-1])\n",
    "                                                    , enc_output)\n",
    "        dec_input = fluid.layers.reshape(dec_target[:, 0], [dec_target.shape[0],1,-1])\n",
    "\n",
    "        for t in range(1, dec_target.shape[1]):\n",
    "            dec_hidden,_ = self.decoder(dec_input,\n",
    "                                            dec_hidden,\n",
    "                                            context_vector)\n",
    "\n",
    "            context_vector, attn = self.attention(fluid.layers.reshape(dec_hidden,[dec_hidden.shape[0],1,-1])\n",
    "                                                    , enc_output)\n",
    "            # using teacher forcing\n",
    "            dec_input = fluid.layers.reshape(dec_target[:, t], [dec_target.shape[0],1,-1])\n",
    "\n",
    "            predictions.append(fluid.layers.reshape(dec_hidden, [dec_hidden.shape[0],1,-1]))\n",
    "            attentions.append(fluid.layers.reshape(attn, [attn.shape[0],1,-1]))\n",
    "\n",
    "        predictions = fluid.layers.concat(predictions, axis=1)\n",
    "        attentions = fluid.layers.concat(attentions, axis=1)\n",
    "\n",
    "        return predictions, attentions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2019-12-24 19:28:01,453 : DEBUG : Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/w3/yc8mtbd91vs80rp79zfgk8x00000gn/T/jieba.cache\n",
      "2019-12-24 19:28:01,455 : DEBUG : Loading model from cache /var/folders/w3/yc8mtbd91vs80rp79zfgk8x00000gn/T/jieba.cache\n",
      "Loading model cost 0.656 seconds.\n",
      "2019-12-24 19:28:02,110 : DEBUG : Loading model cost 0.656 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2019-12-24 19:28:02,112 : DEBUG : Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from utils.data_loader import load_dataset\n",
    "from utils.wv_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    # print('real shape:{}'.format(real.shape))\n",
    "    # print('pred shape:{}'.format(pred.shape))\n",
    "    # print('real:{}'.format(real.numpy()[0]))\n",
    "    # print('pred:{}'.format(pred.numpy()[0]))\n",
    "    # print('pred id of 0:{}'.format(np.argwhere(pred.numpy()[0]==0)))\n",
    "    # 判断logit为1和0的数量\n",
    "    real = fluid.layers.cast(real, dtype=np.int64)\n",
    "    pad_array = fluid.layers.ones_like(real) * word2id['<PAD>']\n",
    "    mask = fluid.layers.logical_not(fluid.layers.equal(real, pad_array))\n",
    "    # print('mask:{}'.format(mask.numpy()[0]))\n",
    "    # 计算decoder的长度\n",
    "    dec_lens = fluid.layers.reduce_sum(fluid.layers.cast(mask, dtype=np.float64), dim=-1)\n",
    "    # 计算loss值\n",
    "    loss_ = fluid.layers.softmax_with_cross_entropy(logits=pred, label=real)\n",
    "    # print('loss_:{}'.format(loss_.numpy()[0]))\n",
    "    # 转换mask的格式\n",
    "    mask = fluid.layers.cast(mask, dtype=loss_.dtype)\n",
    "    # 调整loss\n",
    "    loss_ *= mask\n",
    "    # 确认下是否有空的摘要加入计算\n",
    "    loss_ = fluid.layers.reduce_sum(loss_, dim=-1) / real.shape[0]\n",
    "    # print('loss_ after reduce_sum:{}'.format(loss_.numpy()))\n",
    "    return fluid.layers.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Epoch 0=========================\n"
     ]
    },
    {
     "ename": "EnforceNotMet",
     "evalue": "\n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > paddle::platform::GetTraceBackString<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&&&, char const*, int)\n1   paddle::memory::detail::MetadataCache::load(paddle::memory::detail::MemoryBlock const*) const\n2   paddle::memory::detail::MemoryBlock::split(paddle::memory::detail::MetadataCache*, unsigned long)\n3   paddle::memory::detail::BuddyAllocator::SplitToAlloc(std::__1::__tree_const_iterator<std::__1::tuple<unsigned long, unsigned long, void*>, std::__1::__tree_node<std::__1::tuple<unsigned long, unsigned long, void*>, void*>*, long>, unsigned long)\n4   paddle::memory::detail::BuddyAllocator::Alloc(unsigned long)\n5   void* paddle::memory::legacy::Alloc<paddle::platform::CPUPlace>(paddle::platform::CPUPlace const&, unsigned long)\n6   paddle::memory::allocation::NaiveBestFitAllocator::AllocateImpl(unsigned long)\n7   paddle::memory::allocation::AllocatorFacade::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long)\n8   paddle::memory::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long)\n9   paddle::framework::Tensor::mutable_data(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, paddle::framework::proto::VarType_Type, unsigned long)\n10  float* paddle::framework::Tensor::mutable_data<float>(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, unsigned long)\n11  paddle::operators::MulKernel<paddle::platform::CPUDeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\n12  std::__1::__function::__func<paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::MulKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::MulKernel<paddle::platform::CPUDeviceContext, double> >::operator()(char const*, char const*, int) const::'lambda'(paddle::framework::ExecutionContext const&), std::__1::allocator<paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::MulKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::MulKernel<paddle::platform::CPUDeviceContext, double> >::operator()(char const*, char const*, int) const::'lambda'(paddle::framework::ExecutionContext const&)>, void (paddle::framework::ExecutionContext const&)>::operator()(paddle::framework::ExecutionContext const&)\n13  paddle::imperative::PreparedOp::Run()\n14  paddle::imperative::OpBase::Run(std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > > > > > const&, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > > > > > const&)\n15  paddle::imperative::Tracer::TraceOp(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > > > > > const&, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > > > > > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, boost::variant<boost::blank, int, float, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<int, std::__1::allocator<int> >, std::__1::vector<float, std::__1::allocator<float> >, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >, bool, std::__1::vector<bool, std::__1::allocator<bool> >, paddle::framework::BlockDesc*, long long, std::__1::vector<paddle::framework::BlockDesc*, std::__1::allocator<paddle::framework::BlockDesc*> >, std::__1::vector<long long, std::__1::allocator<long long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, boost::variant<boost::blank, int, float, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<int, std::__1::allocator<int> >, std::__1::vector<float, std::__1::allocator<float> >, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >, bool, std::__1::vector<bool, std::__1::allocator<bool> >, paddle::framework::BlockDesc*, long long, std::__1::vector<paddle::framework::BlockDesc*, std::__1::allocator<paddle::framework::BlockDesc*> >, std::__1::vector<long long, std::__1::allocator<long long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, bool)\n16  void pybind11::cpp_function::initialize<paddle::pybind::BindImperative(pybind11::module*)::$_17, void, paddle::imperative::Tracer&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, pybind11::handle, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, pybind11::handle> > > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, pybind11::handle, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, pybind11::handle> > > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, boost::variant<boost::blank, int, float, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<int, std::__1::allocator<int> >, std::__1::vector<float, std::__1::allocator<float> >, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >, bool, std::__1::vector<bool, std::__1::allocator<bool> >, paddle::framework::BlockDesc*, long long, std::__1::vector<paddle::framework::BlockDesc*, std::__1::allocator<paddle::framework::BlockDesc*> >, std::__1::vector<long long, std::__1::allocator<long long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, boost::variant<boost::blank, int, float, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<int, std::__1::allocator<int> >, std::__1::vector<float, std::__1::allocator<float> >, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >, bool, std::__1::vector<bool, std::__1::allocator<bool> >, paddle::framework::BlockDesc*, long long, std::__1::vector<paddle::framework::BlockDesc*, std::__1::allocator<paddle::framework::BlockDesc*> >, std::__1::vector<long long, std::__1::allocator<long long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >, paddle::platform::CPUPlace const&, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(paddle::pybind::BindImperative(pybind11::module*)::$_17&&, void (*)(paddle::imperative::Tracer&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, pybind11::handle, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, pybind11::handle> > > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, pybind11::handle, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, pybind11::handle> > > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, boost::variant<boost::blank, int, float, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<int, std::__1::allocator<int> >, std::__1::vector<float, std::__1::allocator<float> >, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >, bool, std::__1::vector<bool, std::__1::allocator<bool> >, paddle::framework::BlockDesc*, long long, std::__1::vector<paddle::framework::BlockDesc*, std::__1::allocator<paddle::framework::BlockDesc*> >, std::__1::vector<long long, std::__1::allocator<long long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, boost::variant<boost::blank, int, float, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<int, std::__1::allocator<int> >, std::__1::vector<float, std::__1::allocator<float> >, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >, bool, std::__1::vector<bool, std::__1::allocator<bool> >, paddle::framework::BlockDesc*, long long, std::__1::vector<paddle::framework::BlockDesc*, std::__1::allocator<paddle::framework::BlockDesc*> >, std::__1::vector<long long, std::__1::allocator<long long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >, paddle::platform::CPUPlace const&, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::__invoke(pybind11::detail::function_call&)\n17  pybind11::cpp_function::dispatcher(_object*, _object*, _object*)\n\n----------------------\nError Message Summary:\n----------------------\nPaddleCheckError: Expected desc->check_guards() == true, but received desc->check_guards():0 != true:1.\n at [/home/teamcity/work/ef54dc8a5b211854/paddle/fluid/memory/detail/meta_cache.cc:33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEnforceNotMet\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a905e0ddac0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# print('label shape:{}'.format(label.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;31m# print('pred shape:{}'.format(pred.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/kaikeba/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mparallel_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3653f7ed5d23>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, dec_hidden, enc_output, dec_target)\u001b[0m\n\u001b[1;32m     41\u001b[0m             dec_hidden,_ = self.decoder(dec_input,\n\u001b[1;32m     42\u001b[0m                                             \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                                             context_vector)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             context_vector, attn = self.attention(fluid.layers.reshape(dec_hidden,[dec_hidden.shape[0],1,-1])\n",
      "\u001b[0;32m~/opt/miniconda3/envs/kaikeba/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mparallel_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-eabfe58742dd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hidden, context_vector)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# after concat shape is (batch_size, context_size + embedding_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fc4gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/kaikeba/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mparallel_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_broadcast_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/kaikeba/lib/python3.6/site-packages/paddle/fluid/dygraph/nn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 attrs={\n\u001b[1;32m   1102\u001b[0m                     \u001b[0;34m\"x_num_col_dims\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_flatten_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                     \u001b[0;34m\"y_num_col_dims\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m                 })\n\u001b[1;32m   1105\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/kaikeba/lib/python3.6/site-packages/paddle/fluid/dygraph/layer_object_helper.py\u001b[0m in \u001b[0;36mappend_op\u001b[0;34m(self, type, inputs, outputs, attrs, stop_gradient)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             stop_gradient=stop_gradient)\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_multiple_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/kaikeba/lib/python3.6/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36mappend_op\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2448\u001b[0m                                        \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m                                        \u001b[0;32mif\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2450\u001b[0;31m                                        kwargs.get(\"stop_gradient\", False))\n\u001b[0m\u001b[1;32m   2451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m             \u001b[0mop_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/kaikeba/lib/python3.6/site-packages/paddle/fluid/dygraph/tracer.py\u001b[0m in \u001b[0;36mtrace_op\u001b[0;34m(self, type, inputs, outputs, attrs, stop_gradient)\u001b[0m\n\u001b[1;32m     45\u001b[0m         self.trace(type, inputs, outputs, attrs,\n\u001b[1;32m     46\u001b[0m                    \u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_expected_place\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_mode\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                    not stop_gradient)\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEnforceNotMet\u001b[0m: \n\n--------------------------------------------\nC++ Call Stacks (More useful to developers):\n--------------------------------------------\n0   std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > paddle::platform::GetTraceBackString<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&>(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&&&, char const*, int)\n1   paddle::memory::detail::MetadataCache::load(paddle::memory::detail::MemoryBlock const*) const\n2   paddle::memory::detail::MemoryBlock::split(paddle::memory::detail::MetadataCache*, unsigned long)\n3   paddle::memory::detail::BuddyAllocator::SplitToAlloc(std::__1::__tree_const_iterator<std::__1::tuple<unsigned long, unsigned long, void*>, std::__1::__tree_node<std::__1::tuple<unsigned long, unsigned long, void*>, void*>*, long>, unsigned long)\n4   paddle::memory::detail::BuddyAllocator::Alloc(unsigned long)\n5   void* paddle::memory::legacy::Alloc<paddle::platform::CPUPlace>(paddle::platform::CPUPlace const&, unsigned long)\n6   paddle::memory::allocation::NaiveBestFitAllocator::AllocateImpl(unsigned long)\n7   paddle::memory::allocation::AllocatorFacade::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long)\n8   paddle::memory::AllocShared(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, unsigned long)\n9   paddle::framework::Tensor::mutable_data(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, paddle::framework::proto::VarType_Type, unsigned long)\n10  float* paddle::framework::Tensor::mutable_data<float>(boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, unsigned long)\n11  paddle::operators::MulKernel<paddle::platform::CPUDeviceContext, float>::Compute(paddle::framework::ExecutionContext const&) const\n12  std::__1::__function::__func<paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::MulKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::MulKernel<paddle::platform::CPUDeviceContext, double> >::operator()(char const*, char const*, int) const::'lambda'(paddle::framework::ExecutionContext const&), std::__1::allocator<paddle::framework::OpKernelRegistrarFunctor<paddle::platform::CPUPlace, false, 0ul, paddle::operators::MulKernel<paddle::platform::CPUDeviceContext, float>, paddle::operators::MulKernel<paddle::platform::CPUDeviceContext, double> >::operator()(char const*, char const*, int) const::'lambda'(paddle::framework::ExecutionContext const&)>, void (paddle::framework::ExecutionContext const&)>::operator()(paddle::framework::ExecutionContext const&)\n13  paddle::imperative::PreparedOp::Run()\n14  paddle::imperative::OpBase::Run(std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > > > > > const&, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > > > > > const&)\n15  paddle::imperative::Tracer::TraceOp(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > > > > > const&, std::__1::map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > >, std::__1::less<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, std::__1::vector<std::__1::shared_ptr<paddle::imperative::VarBase>, std::__1::allocator<std::__1::shared_ptr<paddle::imperative::VarBase> > > > > > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, boost::variant<boost::blank, int, float, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<int, std::__1::allocator<int> >, std::__1::vector<float, std::__1::allocator<float> >, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >, bool, std::__1::vector<bool, std::__1::allocator<bool> >, paddle::framework::BlockDesc*, long long, std::__1::vector<paddle::framework::BlockDesc*, std::__1::allocator<paddle::framework::BlockDesc*> >, std::__1::vector<long long, std::__1::allocator<long long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, boost::variant<boost::blank, int, float, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<int, std::__1::allocator<int> >, std::__1::vector<float, std::__1::allocator<float> >, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >, bool, std::__1::vector<bool, std::__1::allocator<bool> >, paddle::framework::BlockDesc*, long long, std::__1::vector<paddle::framework::BlockDesc*, std::__1::allocator<paddle::framework::BlockDesc*> >, std::__1::vector<long long, std::__1::allocator<long long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >, boost::variant<paddle::platform::CUDAPlace, paddle::platform::CPUPlace, paddle::platform::CUDAPinnedPlace, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> const&, bool)\n16  void pybind11::cpp_function::initialize<paddle::pybind::BindImperative(pybind11::module*)::$_17, void, paddle::imperative::Tracer&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, pybind11::handle, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, pybind11::handle> > > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, pybind11::handle, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, pybind11::handle> > > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, boost::variant<boost::blank, int, float, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<int, std::__1::allocator<int> >, std::__1::vector<float, std::__1::allocator<float> >, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >, bool, std::__1::vector<bool, std::__1::allocator<bool> >, paddle::framework::BlockDesc*, long long, std::__1::vector<paddle::framework::BlockDesc*, std::__1::allocator<paddle::framework::BlockDesc*> >, std::__1::vector<long long, std::__1::allocator<long long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, boost::variant<boost::blank, int, float, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<int, std::__1::allocator<int> >, std::__1::vector<float, std::__1::allocator<float> >, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >, bool, std::__1::vector<bool, std::__1::allocator<bool> >, paddle::framework::BlockDesc*, long long, std::__1::vector<paddle::framework::BlockDesc*, std::__1::allocator<paddle::framework::BlockDesc*> >, std::__1::vector<long long, std::__1::allocator<long long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >, paddle::platform::CPUPlace const&, bool, pybind11::name, pybind11::is_method, pybind11::sibling>(paddle::pybind::BindImperative(pybind11::module*)::$_17&&, void (*)(paddle::imperative::Tracer&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, pybind11::handle, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, pybind11::handle> > > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, pybind11::handle, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, pybind11::handle> > > const&, std::__1::unordered_map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, boost::variant<boost::blank, int, float, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<int, std::__1::allocator<int> >, std::__1::vector<float, std::__1::allocator<float> >, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >, bool, std::__1::vector<bool, std::__1::allocator<bool> >, paddle::framework::BlockDesc*, long long, std::__1::vector<paddle::framework::BlockDesc*, std::__1::allocator<paddle::framework::BlockDesc*> >, std::__1::vector<long long, std::__1::allocator<long long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_>, std::__1::hash<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::equal_to<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >, std::__1::allocator<std::__1::pair<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const, boost::variant<boost::blank, int, float, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::vector<int, std::__1::allocator<int> >, std::__1::vector<float, std::__1::allocator<float> >, std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >, bool, std::__1::vector<bool, std::__1::allocator<bool> >, paddle::framework::BlockDesc*, long long, std::__1::vector<paddle::framework::BlockDesc*, std::__1::allocator<paddle::framework::BlockDesc*> >, std::__1::vector<long long, std::__1::allocator<long long> >, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_, boost::detail::variant::void_> > > >, paddle::platform::CPUPlace const&, bool), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::'lambda'(pybind11::detail::function_call&)::__invoke(pybind11::detail::function_call&)\n17  pybind11::cpp_function::dispatcher(_object*, _object*, _object*)\n\n----------------------\nError Message Summary:\n----------------------\nPaddleCheckError: Expected desc->check_guards() == true, but received desc->check_guards():0 != true:1.\n at [/home/teamcity/work/ef54dc8a5b211854/paddle/fluid/memory/detail/meta_cache.cc:33]\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 5\n",
    "BATCH_SIZE = 32\n",
    "X,Y,_ = load_dataset() \n",
    "# X = np.append(X[:,:201], X[:,-1].reshape((-1,1)), axis=1)\n",
    "x_time_steps = X.shape[1]\n",
    "y_time_steps = Y.shape[1]\n",
    "Dataset = np.concatenate([X,Y], axis=1)\n",
    "word2id, id2word = load_vocab()\n",
    "params = {}\n",
    "params[\"vocab_size\"] = len(word2id)\n",
    "params[\"embed_size\"] = 300\n",
    "params[\"enc_units\"] = 512\n",
    "params[\"attn_units\"] = 16\n",
    "params[\"dec_units\"] = 512\n",
    "params[\"batch_size\"] = BATCH_SIZE\n",
    "params[\"epochs\"] = 5\n",
    "params[\"max_enc_len\"] = x_time_steps\n",
    "params[\"max_dec_len\"] = y_time_steps\n",
    "\n",
    "# generator for paddle batch\n",
    "def train_gen():\n",
    "    for row in Dataset:\n",
    "        yield row\n",
    "\n",
    "with fluid.dygraph.guard():\n",
    "    model = Seq2Seq('seq2seq', params)\n",
    "    # Optimizer\n",
    "    adam = fluid.optimizer.Adam(learning_rate=1e-5)\n",
    "    train_reader = paddle.batch(\n",
    "        train_gen, batch_size= BATCH_SIZE, drop_last=True)\n",
    "\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    dy_param_init_value={}\n",
    "    time_start = time_end = None # check elapsed time\n",
    "    avg_loss = -1 # for print info\n",
    "    for epoch in range(epoch_num):\n",
    "        print('='*25 + 'Epoch {}'.format(epoch) + '='*25)\n",
    "        for batch_id, data in enumerate(train_reader()):\n",
    "            if batch_id % 10 == 0:\n",
    "                if time_start is not None:\n",
    "                    time_end = perf_counter()\n",
    "                    print('Elapsed time:{:.2f}'.format(time_end - time_start))\n",
    "                time_start = perf_counter()\n",
    "                if avg_loss != -1:\n",
    "                    print('completed batch {}, loss:{}'.format(batch_id, avg_loss.numpy()))\n",
    "            data = np.array(data).astype('int64').flatten().reshape(BATCH_SIZE, x_time_steps+y_time_steps, 1)\n",
    "            batch_x = data[:,:x_time_steps,:]\n",
    "            batch_y = data[:,x_time_steps:,:]\n",
    "\n",
    "            input = fluid.dygraph.to_variable(batch_x)\n",
    "            label = fluid.dygraph.to_variable(batch_y)\n",
    "            # print('input shape:{}'.format(input.shape))\n",
    "            # print('label shape:{}'.format(label.shape))\n",
    "            enc_output, enc_hidden = model.call_encoder(input)\n",
    "            pred,_ = model(enc_hidden, enc_output, label)\n",
    "            # print('pred shape:{}'.format(pred.shape))\n",
    "            loss = loss_function(label[:, 1:], pred)\n",
    "            # print('loss:{}'.format(loss.numpy()))\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            print('avg_loss:{}'.format(avg_loss.numpy()))\n",
    "            try:\n",
    "                avg_loss.backward()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print('X:{}'.format(batch_x))\n",
    "                print('Y:{}'.format(batch_y))\n",
    "            adam.minimize(avg_loss)\n",
    "            model.clear_gradients()\n",
    "            # for param in model.parameters():\n",
    "            #     dy_param_init_value[param.name] = param.numpy()\n",
    "            # model_states, _ = fluid.dygraph.load_dygraph(\"paddle_seq2seq\")\n",
    "            # model.set_dict(model_states)\n",
    "        \n",
    "            fluid.dygraph.save_dygraph(model.state_dict(), \"paddle_seq2seq\")\n",
    "    \n",
    "    \n",
    "    # 检查是否成功保存模型\n",
    "    restore = model.parameters()\n",
    "    success = True\n",
    "    for value in restore:\n",
    "        if (not np.array_equal(value.numpy(), dy_param_init_value[value.name])) or (not np.isfinite(value.numpy().all())) or (np.isnan(value.numpy().any())):\n",
    "            success = False\n",
    "    print(\"model save and load success? {}\".format(success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaikeba_lecture01",
   "language": "python",
   "name": "kaikeba_lecture01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
